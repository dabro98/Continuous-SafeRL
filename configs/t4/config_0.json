{
    "algorithm": "PPO", 
    "env_path": "boxenvmain/designs/t4_0.json",
    "log_std_init": 0.7,
    "n_steps": 2048,
    "n_epochs": 20,
    "total_steps": 150000,
    "eval_steps": 15000
}

